{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch: A 60 Minute Blitz\n",
    "\n",
    "This is me following along to the [tutorial from the official PyTorch website](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py). Note that I'm also taking some asides and detours as I type the code to investigate interesting detours as I seek to more fully understand the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we need to do is import the torch library. This takes a fair amount of time. Fortunately, this is a one-time operation per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Hello, World example initializes a new tensor of dimensions `[5,3]` that contain random values from whatever the memory was before the call, i.e., it does not zero it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3563e-19, 1.8888e+31, 8.9066e-15],\n",
       "        [1.8888e+31, 6.4639e-04, 6.8608e+22],\n",
       "        [1.7753e+28, 2.0535e-19, 7.5563e+31],\n",
       "        [1.8014e+25, 8.1335e+32, 7.2436e+22],\n",
       "        [7.5554e+28, 2.9635e+29, 2.2087e+03]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next example constructs a tensor, but this time initialized to zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the _type_ of the zeros that you want, e.g., half precision floating point (which is interesting for its performance characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.half)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create it with explicit random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1389, 0.8535, 0.1238],\n",
       "        [0.6640, 0.5807, 0.8310],\n",
       "        [0.2637, 0.3751, 0.5752],\n",
       "        [0.7574, 0.5341, 0.3174],\n",
       "        [0.6864, 0.0092, 0.2743]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you try and use a type that is only supported on GPUs, e.g., `torch.half`, it will throw an error because `torch.rand` by default will construct the type on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_uniform_ not supported on CPUType for Half",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2814bed2e1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_uniform_ not supported on CPUType for Half"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3, dtype=torch.half)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we solve this by first initializing a `cuda` device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass the `cuda` device as a parameter to `torch.rand` which now constructs the tensor on the GPU successfully. This requires 1 time initialization of the CUDA infrastructure (several seconds), again a per-session cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7217, 0.0433, 0.3591],\n",
       "        [0.3684, 0.6777, 0.0998],\n",
       "        [0.4692, 0.1526, 0.0967],\n",
       "        [0.1025, 0.4043, 0.8008],\n",
       "        [0.8335, 0.7324, 0.1650]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3, device=device, dtype=torch.half)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of a tensor is sometimes something that we need to know when debugging. We can do this by using the `size()` member function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors support operations such as addition, which does a memberwise addition of all of the elements across tensors of the same size. Let's create a new tensor, y, of the same size with random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7612, 0.7363, 0.1208],\n",
       "        [0.1691, 0.2136, 0.3752],\n",
       "        [0.9043, 0.7339, 0.3723],\n",
       "        [0.9688, 0.6328, 0.6787],\n",
       "        [0.2761, 0.7061, 0.7134]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5, 3, device=device, dtype=torch.half)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do an implicit add simply by using the plus operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4824, 0.7798, 0.4800],\n",
      "        [0.5376, 0.8916, 0.4751],\n",
      "        [1.3730, 0.8867, 0.4690],\n",
      "        [1.0713, 1.0371, 1.4795],\n",
      "        [1.1094, 1.4385, 0.8784]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can explicitly use the `torch.add()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4824, 0.7798, 0.4800],\n",
      "        [0.5376, 0.8916, 0.4751],\n",
      "        [1.3730, 0.8867, 0.4690],\n",
      "        [1.0713, 1.0371, 1.4795],\n",
      "        [1.1094, 1.4385, 0.8784]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the tensor sizes are mismatched? Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2134, 0.3101],\n",
       "        [0.3345, 0.5142]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.rand(2, 2, device=device, dtype=torch.half)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, we get a runtime error when attempting the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7c8ea62b4603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print(x+z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cases above, we've been adding numbers and producing a new tensor. We can also do in-place addition as well which will replace the value in the tensor for which the `add_()` member is being invoked on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4824, 0.7798, 0.4800],\n",
       "        [0.5376, 0.8916, 0.4751],\n",
       "        [1.3730, 0.8867, 0.4690],\n",
       "        [1.0713, 1.0371, 1.4795],\n",
       "        [1.1094, 1.4385, 0.8784]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we add a scalar to a tensor? Pretty much what you would expect, the scalar gets added to each member of the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4824, 1.7793, 1.4805],\n",
      "        [1.5371, 1.8916, 1.4746],\n",
      "        [2.3730, 1.8867, 1.4688],\n",
      "        [2.0703, 2.0371, 2.4805],\n",
      "        [2.1094, 2.4375, 1.8789]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(y+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and CUDA\n",
    "\n",
    "Tensors can be moved back and forth between CPU and GPU as well. You can use the `to()` method on the tensor to move a tensor back to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_y = y.to(\"cpu\", torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4824, 0.7798, 0.4800],\n",
       "        [0.5376, 0.8916, 0.4751],\n",
       "        [1.3730, 0.8867, 0.4690],\n",
       "        [1.0713, 1.0371, 1.4795],\n",
       "        [1.1094, 1.4385, 0.8784]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation\n",
    "\n",
    "This is the key feature of pytorch (and other deep learning packages) which provides automatic differentiation for all operations on tensors. You can turn on automatic differentiation by setting the `requires_grad=True` on the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6.],\n",
       "        [6., 6.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * 2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-40c0c9b0bbab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "Let's build a neural network using pytorch by first importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9abf303ae56418abf83e1af50a964ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a4c69d9850436284fbc1c39ea6f70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f57e0106c54b179e316a5eb6e7eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf03424688e462ba3128abfa901db60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
